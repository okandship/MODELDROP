# Seedance 2.0: features and capabilities

**Seedance 2.0** is an AI video generation model designed for creators who want **more control** over style, character identity, motion, and continuity. It supports **prompt-based generation** and can also use **reference assets** (images, short video clips, and audio) to steer results toward a specific look and feel.

## Core capabilities

### Multimodal inputs (text + references)
Seedance 2.0 can combine multiple inputs in a single generation:
- **Text prompt** to define what should happen
- **Image references** to lock in subject identity, wardrobe, props, or an art style
- **Video references** to imitate pacing, camera language, and motion patterns
- **Audio references** to guide timing, emotion, and audio-visual alignment

Typical reference limits are described as:
- Up to **9 images**
- Up to **3 videos**
- Up to **3 audio clips**
- Reference video/audio clips often capped around **~15 seconds** each

### Character and brand consistency
A major focus is keeping a subject recognizable across multiple outputs, including:
- facial features and body proportions
- clothing and accessories
- signature props and logos
- stable color palette and lighting cues

This is useful for recurring characters, branded series, mascots, and story-driven content.

### Stronger composition and shot control
Seedance 2.0 is positioned for more predictable framing and cinematic output. It can respond to prompts that describe:
- camera angle (close-up, wide, over-the-shoulder)
- camera motion (dolly, handheld, orbit, track)
- pacing (slow reveal vs. fast action)
- mood (dreamy, gritty, glossy, documentary)

### Multi-shot storytelling and continuity
Instead of producing only isolated clips, Seedance 2.0 is designed to support **coherent sequences**, including:
- multi-scene narratives with consistent identity and style
- smooth transitions between shots
- maintaining scene logic across cuts (location cues, wardrobe continuity, props)

Some workflows also emphasize **extending** or **continuing** an existing shot to build longer sequences.

### Audio guidance, performance, and lip sync
When audio is provided, Seedance 2.0 can use it to influence:
- timing and rhythm (visual pacing aligned to voice/music)
- facial expression and performance cues
- lip movement matching speech (best effort, depends on audio quality and shot framing)

### High-motion and dynamic scenes
Seedance 2.0 is described as capable of handling more complex motion, such as:
- fast camera tracking
- energetic action and collisions
- multi-character movement in the same scene
- dramatic effects and VFX-like styling

## Output controls (commonly available)
Depending on the interface, users typically select:
- **Aspect ratio**: 16:9, 9:16, 1:1, 4:3, 3:4
- **Resolution**: often 720p to 1080p
- **Duration**: commonly 5–12 seconds per generation (varies)

## Common use cases

- **Short-form creator content**: reels/shorts-style clips, animated skits, trend remixes
- **Marketing and brand assets**: product promos, hero scenes, ad variants with consistent identity
- **Previsualization**: cinematic previews for film/game (blocking, camera, mood exploration)
- **Concept iteration**: rapid testing of styles, characters, and shot ideas before a full pipeline
- **Narrative experiments**: multi-shot sequences with recurring protagonists and locations

## Practical prompt tips

### Write prompts that include “film language”
Include specifics like:
- who/what is in frame
- action + intention (“reaches, hesitates, then runs”)
- environment + time (“neon alley at night, light rain”)
- camera behavior (“handheld, tight close-up, quick push-in”)
- mood/style (“high contrast, cinematic, soft bloom”)

### Use references intentionally
- Use **1–3 strong images** to anchor identity/style
- Add **a short reference clip** when you want a particular motion or editing rhythm
- Add **audio** when timing, mood, or speech performance matters

### Iterate without randomness
Change one variable at a time:
- prompt wording
- a single reference image
- a short motion reference
This keeps results easier to diagnose and refine.

## FAQ

### Is Seedance 2.0 text-to-video or image-to-video?
It supports **text-to-video** and can also be guided heavily by **image and video references**.

### How many references can I use?
Commonly described limits are **up to 9 images, 3 videos, and 3 audio clips** in a project (interfaces may vary).

### Can it help keep the same character across multiple clips?
Yes—maintaining character and brand continuity is a primary advertised strength.

### Does it support voice guidance and lip sync?
Audio can guide timing and performance, and the model may attempt lip sync when speech is present.